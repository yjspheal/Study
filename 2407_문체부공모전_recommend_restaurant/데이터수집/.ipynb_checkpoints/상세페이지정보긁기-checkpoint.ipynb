{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89bdfa99",
   "metadata": {},
   "source": [
    "# 기본 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6fb9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "\n",
    "# 페이지 맨 아래까지 스크롤 다운하는 함수\n",
    "def scroll_down():\n",
    "    # 끝까지 스크롤 다운\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # 페이지 로드 대기\n",
    "        time.sleep(2)  # 페이지 로딩 대기 시간 조정 가능\n",
    "\n",
    "        # 새로운 높이 계산\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        # 더 이상 스크롤할 내용이 없으면 종료\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "# 텍스트 찾기 함수\n",
    "def find_all_text(x):\n",
    "    if x:\n",
    "        x_texts = [i.text.strip() for i in x]\n",
    "        x_text = ', '.join(x_texts)\n",
    "    else:\n",
    "        x_text = \"Not found\"\n",
    "    \n",
    "    return x_text\n",
    "\n",
    "# 메뉴 클릭 함수\n",
    "def click_menu(menu):\n",
    "    # 탭 클릭\n",
    "    try:\n",
    "    # CSS 선택자를 사용하여 'veBoZ' 클래스를 가진 <span> 요소 중 텍스트가 menu인 요소 찾기\n",
    "        menu_buttons = driver.find_elements(By.CSS_SELECTOR, 'a._tab-menu span.veBoZ')\n",
    "\n",
    "        # '메뉴' 텍스트를 가진 요소 클릭\n",
    "        for button in menu_buttons:\n",
    "            if menu in button.text:\n",
    "                button.click()\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65763145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome WebDriver 초기화\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "# 네이버 플레이스 켜기 (여기 id 가져오는 코드 필요)\n",
    "url = 'https://m.place.naver.com/restaurant/37690949/home?entry=pll'\n",
    "driver.get(url+'home')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde475a",
   "metadata": {},
   "source": [
    "# 식당 홈 탭 크롤링\n",
    "- 식당 이름\n",
    "- 메뉴 카테고리\n",
    "- 주소\n",
    "- 전화번호\n",
    "- 웹사이트 주소\n",
    "- 영업 시간\n",
    "- 역에서부터의 거리\n",
    "- 서비스 목록\n",
    "- 총 리뷰 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d7fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_page_data():\n",
    "    time.sleep(5)\n",
    "    scroll_down()\n",
    "\n",
    "    # 페이지 소스 가져오기\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # BeautifulSoup 객체 생성\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # 데이터 쌓기\n",
    "    # 가게 이름\n",
    "    try:\n",
    "        restaurant_name = soup.find('span', class_='GHAhO').text.strip()\n",
    "    except:\n",
    "        restaurant_name = float('nan')\n",
    "        \n",
    "    # 업종\n",
    "    try:\n",
    "        category = soup.find('span', class_='lnJFt').text.strip()\n",
    "    except:\n",
    "        category = float('nan')\n",
    "        \n",
    "    # 총 방문자 리뷰 수\n",
    "    try:\n",
    "        count_reviews = soup.find_all('em', class_='place_section_count')\n",
    "        second_count_review = count_reviews[1].text.strip()\n",
    "    except:\n",
    "        second_count_review = float('nan')\n",
    "        \n",
    "    # 주소\n",
    "    try:\n",
    "        address = soup.find('div', class_='O8qbU tQY7D').find('span', class_='LDgIH').text.strip()\n",
    "    except:\n",
    "        address = float('nan')\n",
    "       \n",
    "    # 역 기준 거리\n",
    "    try:\n",
    "        distance = soup.find('div', class_='nZapA').text.strip()\n",
    "    except:\n",
    "        distance = float('nan')\n",
    "\n",
    "    # 영업 시간\n",
    "    try:\n",
    "        business_hours = soup.find('div', class_='O8qbU pSavy').find('span', class_='A_cdD').text.strip()\n",
    "    except:\n",
    "        business_hours = float('nan')\n",
    "\n",
    "    # 전화번호\n",
    "    try:\n",
    "        phone_number = soup.find('div', class_='O8qbU nbXkr').find('span', class_='xlx7Q').text.strip()\n",
    "    except:\n",
    "        phone_number = float('nan')\n",
    "        \n",
    "    # 홈페이지\n",
    "    try:\n",
    "        # 'div' 태그에서 class가 'O8qbU yIPfO'인 요소를 찾고, 그 안에 있는 'a' 태그를 모두 찾기\n",
    "        website_links = soup.find('div', class_='O8qbU yIPfO').find_all('a', class_='place_bluelink')\n",
    "        # website_links_hrefs = [link.get('href') for link in website_links]\n",
    "    except:\n",
    "        website_links = float('nan')\n",
    "        \n",
    "    # 부가 서비스 목록\n",
    "    try:\n",
    "        home_service = soup.find('div', class_='xPvPE').text.strip()\n",
    "    except:\n",
    "        home_service = float('nan')\n",
    "\n",
    "    return restaurant_name, category, second_count_review, address, distance, business_hours, phone_number, website_links, home_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587bc44f",
   "metadata": {},
   "source": [
    "# 메뉴 탭 크롤링\n",
    "- 메뉴 텍스트 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30205946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu_page_data():\n",
    "    #메뉴 탭 클릭\n",
    "    click_menu('메뉴')\n",
    "    \n",
    "    time.sleep(5)\n",
    "    scroll_down()\n",
    "    \n",
    "    # 메뉴 더보기 버튼 클릭\n",
    "    while True:\n",
    "        try:\n",
    "            more_menu_button = driver.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div[6]/div/div[1]/div[2]/div/a')\n",
    "            if more_menu_button.is_displayed() and more_menu_button.is_enabled():\n",
    "                more_menu_button.click()\n",
    "                time.sleep(2)  # 클릭 후 로딩 대기\n",
    "            else:\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "    \n",
    "    # 페이지 소스 가져오기\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # BeautifulSoup 객체 생성\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # 메뉴 텍스트 내용 긁어오기\n",
    "    try:\n",
    "        menu_texts = soup.find_all('div', class_='MXkFw')\n",
    "        menu_contents = [menu_text.text.strip() for menu_text in menu_texts]\n",
    "    except:\n",
    "        menu_contents = float('nan')\n",
    "        \n",
    "    # 결과 반환\n",
    "    return menu_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162e831",
   "metadata": {},
   "source": [
    "# 정보 탭 크롤링\n",
    "- 소개글\n",
    "- 편의시설 및 서비스\n",
    "- 주차\n",
    "- 좌석, 공간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81341ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_page_data():\n",
    "    # 정보 탭 클릭\n",
    "    click_menu('정보')\n",
    "\n",
    "    time.sleep(5)\n",
    "    scroll_down()\n",
    "\n",
    "    # 페이지 소스 가져오기\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # BeautifulSoup 객체 생성\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # 데이터 쌓기\n",
    "    # 소개글\n",
    "    #     try:\n",
    "    #         introduce_button = driver.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div[5]/div/div[1]/div/div/div[2]/a')\n",
    "    #         introduce_button.click()\n",
    "    #         introduce = soup.find('div', class_='T8RFa').text.strip()\n",
    "    #     except:\n",
    "    #         introduce = float('nan')\n",
    "    \n",
    "    # 편의 시설 및 서비스\n",
    "    try:\n",
    "        service = soup.find_all('div', class_='owG4q')\n",
    "        services = find_all_text(service)\n",
    "        \n",
    "    except:\n",
    "        services = float('nan')\n",
    "    \n",
    "    # 주차\n",
    "    try:\n",
    "        parking = soup.find('div', class_='TZ6eS').text.strip()\n",
    "    except:\n",
    "        parking = float('nan')\n",
    "    \n",
    "    # 좌석, 공간\n",
    "    try:\n",
    "        seat = soup.find_all('li', class_='Lw5L1')\n",
    "        seats = find_all_text(seat)\n",
    "        \n",
    "    except:\n",
    "        seats = float('nan')\n",
    "        \n",
    "    return services, parking, seats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d445a3c",
   "metadata": {},
   "source": [
    "# 리뷰 탭 크롤링\n",
    "- 리뷰 텍스트 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가한 코드\n",
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n",
    "\n",
    "def scroll_up():\n",
    "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    time.sleep(2)  # 스크롤 후 페이지 로딩 대기\n",
    "    \n",
    "def add_query_param_to_url(url, param_name, param_value):\n",
    "    \"\"\"현재 URL에 쿼리 파라미터를 추가하여 반환\"\"\"\n",
    "    url_parts = list(urlparse(url))\n",
    "    query = dict(parse_qs(url_parts[4]))\n",
    "    query[param_name] = param_value\n",
    "    url_parts[4] = urlencode(query, doseq=True)\n",
    "    return urlunparse(url_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a66cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_page_data():\n",
    "    # 리뷰 탭 클릭\n",
    "    click_menu('리뷰')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # 최신순 버튼 클릭\n",
    "    # 처음에는 이런 코드였는데, scroll_up(), scroll_down() 사용으로 화면에 버튼이 안보이면 최신순 버튼 클릭이 잘 안돼서..ㅠㅠ\n",
    "    # 또 얘가 되면 키워드 리뷰 더보기 클릭이 안되고.. 이러저러하다가 뭔가 복잡해졌습니다\n",
    "    # recent_button = driver.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div[6]/div[2]/div[3]/div/div[2]/div[1]/span[2]/a')\n",
    "    # recent_button.click()\n",
    "    # time.sleep(3)\n",
    "    \n",
    "# scroll_up()\n",
    "    current_url = driver.current_url\n",
    "    updated_url = add_query_param_to_url(current_url, 'reviewSort', 'recent')\n",
    "    driver.get(updated_url)\n",
    "    time.sleep(5)  # 페이지 로딩 대기\n",
    "    \n",
    "    # 키워드 리뷰 데이터 쌓기\n",
    "    while True:\n",
    "        try:\n",
    "            # \"더보기\" 버튼의 XPath\n",
    "            more_review_keyword_xpath = '/html/body/div[3]/div/div/div/div[6]/div[2]/div[1]/div/div/div[2]/a[1]'\n",
    "\n",
    "            # \"더보기\" 버튼 요소 찾기\n",
    "            more_review_keyword = driver.find_element(By.XPATH, more_review_keyword_xpath)\n",
    "\n",
    "            # \"더보기\" 버튼 클릭\n",
    "            more_review_keyword.click()\n",
    "\n",
    "            # 클릭 후 페이지 로딩 대기\n",
    "            time.sleep(2)\n",
    "\n",
    "            # 'a' 태그의 'dP0sq' 클래스를 가진 요소 찾기\n",
    "            dP0sq_elements = driver.find_elements(By.CLASS_NAME, 'dP0sq')\n",
    "\n",
    "            if not dP0sq_elements:\n",
    "                # 'dP0sq' 클래스를 가진 요소가 없으면 루프 종료\n",
    "                break\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            # \"더보기\" 버튼을 찾을 수 없으면 루프 종료\n",
    "            break\n",
    "\n",
    "    scroll_down()\n",
    "\n",
    "    # 리뷰 키워드 정보 추출\n",
    "    # 페이지 소스 가져오기\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # BeautifulSoup 객체 생성\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # 모든 't3JSf' 태그와 'CUoLy' 태그를 찾음\n",
    "    review_keywords_elements = soup.find_all('span', class_='t3JSf')\n",
    "    review_keywords_count_elements = soup.find_all('span', class_='CUoLy')\n",
    "\n",
    "    # 두 리스트의 길이를 확인하여 최소 길이만큼 순회\n",
    "    min_length = min(len(review_keywords_elements), len(review_keywords_count_elements))\n",
    "\n",
    "    # 키워드 데이터 리스트 생성\n",
    "    review_keywords_data = []\n",
    "\n",
    "    # 순서대로 함께 추가\n",
    "    for i in range(min_length):\n",
    "        review_keywords = review_keywords_elements[i].text.strip()\n",
    "        review_keywords_count = review_keywords_count_elements[i].text.strip()\n",
    "        review_keywords_data.append({\n",
    "            'keyword': review_keywords,\n",
    "            'count': review_keywords_count\n",
    "        })\n",
    "    \n",
    "    scroll_down()\n",
    "    \n",
    "    # 끝까지 스크롤 다운 및 더보기 클릭 반복\n",
    "    i = 0\n",
    "    while i < 10:\n",
    "        # 끝까지 스크롤 다운\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)  # 페이지 로딩 대기 시간 조정 가능\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # 더보기 버튼 클릭\n",
    "        try:\n",
    "            more_review_button = driver.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div[6]/div[2]/div[3]/div[2]/div/a')\n",
    "            if more_review_button.is_displayed() and more_review_button.is_enabled():\n",
    "                more_review_button.click()\n",
    "                time.sleep(2)  # 클릭 후 로딩 대기\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "        except ElementNotInteractableException:\n",
    "            break\n",
    "            \n",
    "    # 개별 리뷰 더보기 버튼\n",
    "    # 초기 XPath\n",
    "    base_xpath = '/html/body/div[3]/div/div/div/div[6]/div[2]/div[3]/div/ul/li[{}]/div/div[4]/a'\n",
    "\n",
    "    # 버튼을 순차적으로 클릭\n",
    "    button_index = 1\n",
    "    while True:\n",
    "        try:\n",
    "            # 현재 XPath\n",
    "            current_xpath = base_xpath.format(button_index)\n",
    "\n",
    "            # 해당 XPath에 해당하는 요소가 있는지 확인\n",
    "            button = driver.find_element(By.XPATH, current_xpath)\n",
    "\n",
    "            # 요소가 있다면 클릭하고 인덱스를 증가시킴\n",
    "            button.click()\n",
    "            time.sleep(2)  # 클릭 후 페이지 로딩 대기\n",
    "            button_index += 1\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    scroll_up()\n",
    "        \n",
    "    while True:\n",
    "        try:\n",
    "            # CSS 선택자를 사용하여 'sIv5s WPk67' 클래스를 가진 <a> 태그 찾기\n",
    "            review_buttons = driver.find_elements(By.CSS_SELECTOR, 'a.sIv5s.WPk67[role=\"button\"]')\n",
    "\n",
    "            if not review_buttons:\n",
    "                # 더 이상 클릭할 버튼이 없으면 종료\n",
    "                break\n",
    "\n",
    "            for button in review_buttons:\n",
    "                try:\n",
    "                    button.click()\n",
    "                    time.sleep(2)  # 클릭 후 페이지 로딩 대기\n",
    "                except ElementNotInteractableException:\n",
    "                    continue\n",
    "        except NoSuchElementException:\n",
    "            print(\"리뷰 더보기 버튼을 찾을 수 없습니다.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "            break\n",
    "            \n",
    "    scroll_down()\n",
    "\n",
    "    # 페이지 로드 후 HTML 소스를 BeautifulSoup로 파싱\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        review_texts = soup.find_all('span', class_='zPfVt')\n",
    "        keyword_review_texts = soup.find_all('div', class_='ERkm0')\n",
    "    except:\n",
    "        review_texts = float('nan')\n",
    "        keyword_review_texts = float('nan')\n",
    "\n",
    "    # 텍스트 추출\n",
    "    review_text_list = [span.get_text() for span in review_texts]\n",
    "    keyword_review_texts_list = [div.get_text() for div in keyword_review_texts]\n",
    "    \n",
    "    return review_keywords_data, review_text_list, keyword_review_texts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e0e4aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['미포리1987에서 주말 런치타임 가졌어요:) 여유로운 분위기와 맛, 친절하심, 날씨까지 어느하나 빠지지 않던  식사시간이었어요! 메뉴외 음료가 다양해서 양식 좋아하시면 호불호없이 즐기실 수 있는 맛집이랍니당\\n국물치킨은 다음에 또 생각날꺼 같아요😀',\n",
       " '샐러드가 신선하고 파스타맛이 좋음\\n갈비찜 고기가 좀 퍽퍽한 것만 제외하면\\n맛이 좋고 재방문 하고 싶어오',\n",
       " '좋아요',\n",
       " '가격도 괜찮고 맛도 좋습니다👍🏻👍🏻',\n",
       " '좋아요 ',\n",
       " '굿',\n",
       " '매콤한 갈비찜과 청양크림 파스타 주문했는데\\n둘다 넘 맛있었어요☺️👍🏻',\n",
       " '대흥의 레전드 아니 마포의 레전드 양식집 ! 국물치킨과 크림파스타가 정말 맛있습니다 :)',\n",
       " '4번정도 방문했는데 복불복이 좀 있네요 ^^ 가격대비 생각했을때 앞으로는 안갈꺼같아요.',\n",
       " '맛있어요.\\n흠이라면 양이 만족스럽지 않다는것!!',\n",
       " '감바스, 새우 크림파스타, 제주 협재 볶음밥, 감튀 먹었는데 오늘도 넘 맛있네용!!😋\\n특히 감바스랑 같이 먹는 먹물빵 폼이 미쵸써요ㅠ🫢\\n또 올껍니당 경의선 숲길 데뚜로 추천해요👍🏻👍🏻',\n",
       " '미취학 아이와 가서 먹기에도 가정식 파스타처럼 간이 좋고 맛있습니다. 저희 집 아이는 매우 좋아해요.\\n메뉴중에 no 메뉴 파스타?를 어제 주문해서 먹었는데 이것도 매우 좋았습니다!!',\n",
       " '학생때부터 자주 다니던 파스타 맛집이에요🥰 스타터인 브루스케타부터 메인 메뉴인 파스타, 뇨끼 전부 맛있어요😋 뇨끼떡볶이는 처음 먹어보는 메뉴인데 색다르면서 술안주로도 좋을 것 같아요. 경의선 숲길 근처 데이트 장소로 추천해요!! ',\n",
       " '주말 저녁에 데이트로 갔는데 너무 힐링되는 시간🤭 실제로 보니 은은한 조명에 가게 인테리어가 너무 예뻐 분위기가 좋았어요!!! ❣️ 데\\n이트, 소개팅 장소 강추🤭마포리의 시그니처 국물치킨과 꽃게향 가득 쉬림프비스크 파스타도 먹었습니당👏🏻👏🏻 이런 이색적인 메뉴가??\\n시원한듯한 국물과 바삭한 치킨, 숙주와 조합 강추니 꼭 드셔보시구요. 숙주가 있어서 건강한 느낌도 있어요!  그리고 파스타는 쉬...',\n",
       " '맛은 있지만 양이적고 비싼편입니다',\n",
       " '음식이 정말 맛있어요 감튀랑 파스타는 블로그 뒤지고 간거였는데 남들이 추천하는건 다 이유가 있더라고요 무조건 강추예요! 딸아이들이 너무 맛있다고 5분만에 흡입해버려서 전 크림만 먹을 수 있었는데 ㅠㅠ 그래도 행복했다고 말하고 싶네요 ㅋㅋ 감튀는 무조건 먹어야해요 소스 예술이예요!',\n",
       " '마포리 처음 생겼을 때부터 다녔어요. 13000원이던 시절부터..음식도 맛있고, 메뉴도 다양하고, 부족한 게 없어요. 다만 모두 좋아해서 요즘같은 연말엔 예약 필수!',\n",
       " '여기 넘 맛잇고 좋아요 가격대비진짜훌륭해여 레몬에이드 양 짱많아여  요즘 이런곳 드물어여 ㅜㅜ  홀직원부터 사장님까지 다 친절그자\\n체..',\n",
       " '진짜 맛있음 .... 치즈 완전 제대로에다가 재료가 다 신선해서 너무 맛있게 먹었어요 다음에 또 가서 다른 메뉴도 먹어보고 싶은 집',\n",
       " '서버분이 정말 친절하시고, 매뉴를 메모지에 적는게 좋았습니다! \\n너무 맛있게 잘 먹었습니다. ',\n",
       " '대흥역 근처 산책로 옆에 있고 가끔 친구들이랑 방문하는 식당이에요 음식이 고급진 맛이기도 하고 분위기도 좋아서 양식 땡길때마다 갑\\n니다 특히 시그니처인 뇨끼떡볶이랑 다른 양식 메뉴 같이 시키면 조합이 진짜 잘맞아요!!!',\n",
       " '대흥역이랑 경의선 숲길에서 가까워서 밥먹구 산책하고 주변에 이쁜 카페가기 넘 좋아욧!!😋\\n지금 다음에 방문하면 감튀서비스 주시는 이벤트도 하고 계셔서 또갈라구요🫶\\n안에 인테리어도 크리스마스 분위기여서 포근하고 좋아요🫢',\n",
       " '리조또가 진짜 맛있었어요 양식 생각나면 여기 자주 이용할것같아요 ㅎㅎ',\n",
       " '진짜 맛있어요 특히 스테이크 정말 맛있어요!!!',\n",
       " '대흥역에서 가깝고 오래된 맛집 입니다!\\n항상 친절하시고 음식도 빨리 나와서 좋아요 :)\\n또 생각 날 때마다 방문 하겠습니다!!',\n",
       " '식사도 빨리나오고 가격대비 맛있어요',\n",
       " '맛있어요 마포리!',\n",
       " '분위기도좋은데, 파스타랑 스테이크가 진짜\\n맛있습니다!!! 재방문의사 100%',\n",
       " '친절하고 맛있는 맛집이에요!!',\n",
       " '요즘 청첩장 모임하느라 여러 음식점을 다니는데 친절과 맛 분위기 다 모두 너무너무 만족하여 리뷰 남깁니다👍🏻 얘기하기도 좋고 맛도 좋아서 모두가 만족했어요! 다음에 또 올게요🥰',\n",
       " '가성비 좋은 파스타집이에요. \\n엄청 고급스러운 맛은 아니지만 가격대에서 최대의 맛을 구현한듯한 맛이에요. 서빙하시는 분 센스도 좋으시고 엄청 친절하세요! ',\n",
       " '뇨끼떡볶이에 뇨끼가 좀 더 있었으면 좋겠어요.. 전 엄마와 방문했는데 연인끼리 친구끼리 방문도 많은 거 같아요. 두 메뉴 다 맛있게 먹었습니다.',\n",
       " '진짜 간만에 맛잇는 파스타집이엿어요~~\\n데이트하러가기좋을것같아용\\n',\n",
       " '번창하세요! 무조건 또 갑니다!',\n",
       " '마포리 신메뉴가 나와서 먹어보러왔어요!!  엄청 큼직한 부라타치즈가 들어간 샐러드는 소스가 상큼하니 넘 맛있더라구요~~ 배 많이 안\\n고픈날엔 요거 하나랑 와인한잔 하면 딱 좋을거같아요^^  오늘은 배고파서 리조또도 시켰어요! 이집을 올때마다 항상 평균이상은 하는거\\n같아요 넘 잘먹고가요~~^^  부라타치즈는 또 먹으러 와야겠어요 ~~~😻😻',\n",
       " '리뷰를 보고 가장 맛있다고 추천해준 메뉴를 주문했다.  떡볶이를 좋아하는 아들과 갔는데~  양이 살짝 부족하지만 소스는 맛있다.  양송이 스프의 고급진 맛?이라고 표현하고 싶다.',\n",
       " '파스파 맛있어요~',\n",
       " '버섯득셸 파케리파스타 완전맛있어요...😍💞💞\\n저는 혼밥했는데 혼밥도 무리없었고 친구랑 같이와도 좋을 것 같아요! 담에는 친구랑 재방문하려고요ㅎㅎ \\n식당분위기도 좋고 인테리어도 맘에들었습니다ㅎㅎ ',\n",
       " '맛있어요!',\n",
       " '매장분위기도 좋고 사장님도 너무 친절하세요! 음식도 맛있었습니다🥰🥰',\n",
       " '좋아요! 맛있어요! 뇨끼떡볶이 강추인게, 가운데 치즈랑도 너무 잘어울려요 ◡̈ ',\n",
       " '너무 맛있게먹느라 사진을 못찍었는데 너무 친절하시고 음식도 맛있어서 너무 만족했습니다🥰❣️ 다음에 또 방문하고싶을정도였어요~ 추천합니다!👍❤️',\n",
       " '일주일새 2번을 방문하고 도무지 이건 아니다라는 생각 때문에 다른 소비자들을 위해서 글을 올립니다. 성인 2~3명, 초등생 2명으로 방\\n문할 때 마다 적지않은 메뉴를 시키고 1시간 조금 넘게 조용하게 식사를 했던 고객입니다  2번 연속 방문동안 느낀 점은 전체적으로 정말 \\n불친절하다, 메뉴를 하나하나 더 주문하면서 눈치를 봐야한다 라는 생각을 너무 많이 들게 하네요 오늘은 라스트 오더전에 빵하나 ...',\n",
       " '맛있고 메뉴가 특이해서 좋았어요.\\n넓은 매장은 아니라 예약했는데 가볍게 가기 좋아요',\n",
       " '뇨끼 떡볶이 땡겨서 먹고왔어요 :)  맵찔이라 쫌 매콤한데 리코타 얹어서 먹으면 딱좋더라구요 ^^  임산부라 술은 못마시지만 와인이랑 \\n먹으면 너무너무 잘어울릴거같아요!!  애기 낳고 또 먹으러 올게요…!!!😁👍✨',\n",
       " '리뉴얼 하고 처음 갔는데 여전히 맛있네요 ~ 메뉴 전부 다 맛있었고 음식도 금방 나왔어요 !',\n",
       " '오늘도 역시 맛있었습니다. ^^',\n",
       " '항상 친절하게 응대해주셔서 기분 좋은 곳',\n",
       " '맛있었어요 ㅎ',\n",
       " '크리스마스 특별 메뉴 진행한다고 해서 예약했어요 ㅋㅋ 코스요리 정갈하고 메뉴 하나 버릴거 없이 다 너무 맛있었어요! 너무 맛있어서 요\\n리 나올때마다 흡입해서 순식간에 해치웠네요 ㅋㅋ직원분이 메뉴 하나하나 다 설명해주시는데 특별한 곳에서 대접 받는 기분이 들었고 맛\\n도 맛이지만 요리 비쥬얼이 어쩜 이리 이쁜지 ㅋㅋㅋ 눈으로 먹고 입으로 먹고 서비스 좋고 가게도 너무 깔끔하고 분위기도 좋고 ! ...',\n",
       " '맛있어요옹~',\n",
       " '친한 언니들과 좋은시간 가졌어요. 음식이 맛있어서 더 즐거웠습니다. 스테이크도 맛있었지만 사이드인  알감자가 미친 맛이어서 깜짝 놀랐어요~~다음에 또 가고 싶어요^^',\n",
       " '맛있어요 분위기좋구',\n",
       " '음식이 다 맛있어요~특히 뇨끼 떡볶이는 또 맛봐야하는 맛이에요.직원분들도 친절하세요~~',\n",
       " '회사 근처라 꾸준히 방문하는 식당입니다. 항상 맛있어요!',\n",
       " '분위기도 좋고 파스타도 넘넘 맛있었어요!!  비싸고 맛있는집은 많은데 가격대도 적당하고  가성비 좋은곳이네요 ^^  잘먹었습니당 또올\\n게요 😻👍',\n",
       " '오랜만에 가니 매장이 넓어졌네요. 국물치킨, 뇨끼떡볶이, 청양크림파스타 언제 먹어도 맛있어요. 저희 고정메뉴에요. 퓨전양식 땡긴다면 추천입니다!',\n",
       " '맛있어요',\n",
       " '맛있어요!',\n",
       " '진짜 맛있어요!',\n",
       " '직장 근처에 있어서 몇 번 방문했는데 맛있네요❤️',\n",
       " '맛있어요 ',\n",
       " '맛있어요.... ㅎㅎㅎㅎㅎㅎ 가격도 일반 파스타 만 초중반대면 적당한 편이에요. 뇨끼 떡볶이랑 협재 볶음밥 먹었는데 많이 자극적이지 않\\n으면서 계속 땡기는 맛이에요 흑흑 다음에 또 와서 먹어보고 싶은 메뉴도 많았구요. 테이블은 4테이블 정도로 약간 협소한 편이었지만 분\\n위기 좋고 맥주 하이볼 등 음료 메뉴도 많아서 좋았어요!  소소한 기념일때 와도 좋을 듯한 느낌?ㅎㅎ',\n",
       " '',\n",
       " '떡볶이 떡이 새알처럼 동그랗게 나오는데 맛있어요',\n",
       " '음식 맛있어요!',\n",
       " '',\n",
       " '대학가라고 생각하면 가성비가 좋은거같아요!  생맥주가 없고 글라스 와인도 없고 바틀 비어 라인업은 제 스타일은 아닌것들만 구비되어 있어서 저는 개인적으로 재방문의사는 없습니다',\n",
       " '좋아요 ',\n",
       " '메뉴가 다 맛있어요',\n",
       " '유명하다고 해서 방문해봤는데 맛이 특별하지는 않았지만 괜찮았습니다.',\n",
       " '가성비 좋구 무엇보다 모든 메뉴 맛있어요 ',\n",
       " '파스타 너무 맛있는데 3인분 시켜야만 배부르게 먹을수있을거같아요',\n",
       " '진짜 맛있어요!! ',\n",
       " '메뉴 다 맛있어요',\n",
       " '항상 뇨끼떡볶이 시켜요. 시간 지나면 생각나더라구요😇 파스타 등 다른 메뉴들도 정말 맛있어요!',\n",
       " '다른메뉴도 궁금해요.',\n",
       " '협재볶음밥 맛있었어요👍',\n",
       " '뇨기 처음 먹어봤는데 크림이 맛잇어용ㅋ',\n",
       " '굿',\n",
       " '맛있어여',\n",
       " '.',\n",
       " '최고에용 마포리는 매일먹어요 뇨끼, 새우청량크림파스타 봉골레 모두좋아요',\n",
       " '맛있어요🍝',\n",
       " '좋아요',\n",
       " '최고',\n",
       " '1인 1메뉴, 4명이라 여러가지 맛볼 수 있었다. 별표로 표시해 둔 메뉴 위주로 주문~겹치는 느낌없이 서로 잘 어울렸다.',\n",
       " '굿',\n",
       " '굿',\n",
       " '양은 좀적지만 맛있게 잘먹었어요',\n",
       " '맛있어요!',\n",
       " '너무너무 맛있었어요!! 못먹어본메뉴들 또 먹으러가보려구요:)',\n",
       " '맛있어요! 분위기도 좋고, 종종 가요',\n",
       " '뇨끼떡볶이 맛있어요🙂',\n",
       " '굿',\n",
       " '좋아요',\n",
       " '강추합니다!!',\n",
       " '맛잇어요',\n",
       " '양에 비해 가격대는 좀 있는 것 같지만 음식은 항상 맛있어요! 매장이 넓진 않아서 웨이팅도 자주 걸리니 오시는 분들은 참고하시는게 좋을 것 같아요 :)',\n",
       " '오랜만에 매장 가서 먹었는데 찹스테이크는 맛있었구 뇨끼떡볶이는 아쉬웠어요ㅠ',\n",
       " '이번이 두번째 방문이었어요! 여긴 한라산 소주가 있답니다 💓 요리도 아주 맛있고 인테리어도 이뻐요 💕',\n",
       " '',\n",
       " '포장해서 먹어도 맛있어요! 찹스테이크랑 라구파스타 자주 먹어요!',\n",
       " '굿',\n",
       " '준이가 추천하는 맛집❤️',\n",
       " '색다른 곳이었어요.',\n",
       " '매번 존맛존맛',\n",
       " '갈 때마다 맛있었어요.  결혼1주년이라 점심은 차타고 나가서 다른 곳에서 먹고와서 집에서 쉬다 저녁은 슬리퍼 끌고 집근처 마포리로 갔\\n어요. 가까운 곳에 맛집 있어서 좋아요. 이 두 메뉴는 처음 먹어보는데 역시나 맛있고 양도 넉넉. 국물치킨 아래 깔린 숙주의 양을 봐도 넉\\n넉한 인심👍🏽  저녁이고 술을 팔아서 그런지 음악이나 분위기가 낮과는 달라서 실은 제 스타일은 아니었고, 음악이 둥둥 거려서 실...',\n",
       " '진심 맛있다... ㅜㅠ',\n",
       " '대박입니다👍다른  메뉴도 너무 궁금해지는 맛!!!',\n",
       " '맛있어요~~~~~',\n",
       " '맛있습니다',\n",
       " '조하',\n",
       " '맛있어요',\n",
       " '맛있어요',\n",
       " '퓨전요리, 전반적으로 맛있어요!',\n",
       " '찹스테이크랑 라구파스타 정말 맛있게 먹었어요!',\n",
       " '맛있어요! 오랫동안 가고있는 식당입니다',\n",
       " '진짜 맛있었어요..... 화장실도 좋고 맛도 기대 이상이고 또 방문할 거에요!\\n잘 먹고 갑니당 ㅎㅎ 번창하세요~!☺️',\n",
       " '음식 진짜 맛있습니다 강력추천',\n",
       " '2번째 방문이구 오늘도 다 다른 메뉴만 시켰는데  다 너무 맛있었어요!! 정말 맛있었어요!!',\n",
       " '좋아용',\n",
       " '첫 방문이었는데 너무 맛있었어요!!!',\n",
       " '청양크림파스타랑 뇨끼 떡볶이 먹었는데 맛있어요!',\n",
       " '굿. 맛있어요',\n",
       " '',\n",
       " '쉬림프 비스큐 파스타\\n꽃게맛이 가득해요 너무 맛있었습니다 :)',\n",
       " '시험 끝나고 따사로운 햇빛을 만끽하며 가서 그런지 맛있게 먹었다',\n",
       " '추운데오래기다렷다고 따뜻한물도주시고서비스도주셨어요',\n",
       " '좋아요',\n",
       " '좋아여',\n",
       " '까르보나라랑 먹물빵 포장해서먹었는데 맛있었어요 가격도좋고 친절하고 맛있어용 또가려구여',\n",
       " '👍🏻',\n",
       " '굿',\n",
       " '남자친구랑 가기좋은곳이에요~ 가성비 좋습니당',\n",
       " '진짜 맛있어요!!!! 사장님이 친절하시고 음식도 빨리 나와용! 기본으로 주신 샐러드 맛있어요ㅎㅎ',\n",
       " '아주맜있ㅇ오ㅛㅇ',\n",
       " '파스타 맛있어요^^',\n",
       " '가족들이랑 맛있는 저녁 한끼 먹으러 왔는데 정말 만족하고 돌아갑니다 추천드립니다!',\n",
       " '너무 좋은 맛집 발견~또갈께요 ㅎ',\n",
       " '❤️솔직히 마포리는 별점 다섯개 아니고 오십개드려야합니다❤️ 생일날 꼭 마포리에서 먹고싶어서 분당주민이 공덕역 근처 호텔예약했습\\n니다 얼마나 맛집인지 감이 오시나요..?  시국이 시국인지라 포장주문했구요 정말 꼼꼼한포장에 수저랑 피클도 넉넉히 챙겨주셔서 감동이\\n었어요 !!! 여기 피클은 그냥 새콤하기만 한게 아니라 올리브도 들어가있어서 아주 단짠단짠 와인안주로 굳입니다  메뉴는 마포리...',\n",
       " '자몽에이드도 마싯고 파스타도 맛있어요!',\n",
       " '',\n",
       " '굿',\n",
       " '완전 맛있습니다ㅜㅜㅠ 서강대 맛집이에요',\n",
       " '',\n",
       " '굿',\n",
       " '가격도 맛도 좋습니다',\n",
       " '꾸덕해서 좋아용',\n",
       " '맛있고 가격도 합리적이어서 만족했어요!',\n",
       " '#파스타 #리조또 #대흥역',\n",
       " '맛 좋아요~ 가성비 짱입니다! 감바스와 먹물빵,  꼭 먹어보세요~^^',\n",
       " '맛있어요 뇨끼와 감바스 짱! 런치서비스로  주신 샐러드도 맛있어요',\n",
       " '스테이크가 가격 대비 구성이 좋아요 배는 조금도 안 고프고 약속이 있어서 그냥 먹는 척만 좀 하자는 생각이었는데 맛있어서 꽤 먹었습니다',\n",
       " '여자친구랑친구들모임으로  가벼운마음으로 방문했었습니다  마포리 스테이크 크으 정말 최고였습니다 . 특히 직원분들 너무 설명 을 잘\\n해주시더라구요 !!! 제방문의사 100프로!!!',\n",
       " '가격대가 인근 상점에 비해 비싸지만, 맛있었습니다. 조그만 가게라 일찍 안 가면 테이블이 꽉 차서 못 먹는다는 단점이 있어요',\n",
       " '퓨전 요리에요. 국물치킨도 맛있고 뇨끼떡볶이도 너무 맛있어요!',\n",
       " '👍',\n",
       " '떡볶이가 대박입니다!! 공간은 협소해요.. 그래도 직원들이 친절해서 괜찮습니다',\n",
       " '음식은 더할나위없이 맛있었구요 맥주한잔 할까해서 맥주랑 곁들여 먹었는데 맥주를 계속 시키게 되더라구요',\n",
       " '맛있어요 근데 자리 간격이 좁아서 불편했어요',\n",
       " '진짜 맛있어요!!!!!! 베스트 메뉴에 있는 떡볶이 꼭 드셔보시길 추천합니다:)',\n",
       " '청양고추크림파스타 추천합니다. 협재볶음밥은 음식이 변한건지 상한 냄새가 약간 났어요. 비추합니다.',\n",
       " '떡볶이뇨끼 맛있어요 ',\n",
       " '마포리 다닌지 오래돼서 대부분의 메뉴를 먹어봤는데, 진짜 다 맛있어요! 재방문 하시는 분들은 새로운 메뉴도 과감하게 시도해보셔도 될 것 같아요! ',\n",
       " '한 번 가서 먹기 나쁘진 않음',\n",
       " '요런곳을 맛집이라고 하죠\\n뇨끼치즈떡볶이 징짜 맛나요\\n처음맛보는맛~!̆̈ ',\n",
       " '맛있어요!',\n",
       " '와인 가격도 합리적이고 음식도 진짜 맛있어요! 강추합니다!!!',\n",
       " '맛있어요...\\n가격은 보통..',\n",
       " '너무 맛있었어용 ㅎ  두명이서  세그릇 뚝닥 하구 나왔습니당 ~~.ᐟ!',\n",
       " '소규모라 대화하기 좋고 맛있게 먹었습니다^^']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_page_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab973c1",
   "metadata": {},
   "source": [
    "* 개별 리뷰의 키워드 버튼 클릭 코드만 따로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abdb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 리뷰의 키워드 버튼 클릭\n",
    "while True:\n",
    "    try:\n",
    "        # CSS 선택자를 사용하여 'sIv5s WPk67' 클래스를 가진 <a> 태그 찾기\n",
    "        review_buttons = driver.find_elements(By.CSS_SELECTOR, 'a.sIv5s.WPk67[role=\"button\"]')\n",
    "\n",
    "        if not review_buttons:\n",
    "            # 더 이상 클릭할 버튼이 없으면 종료\n",
    "            break\n",
    "\n",
    "        for button in review_buttons:\n",
    "            try:\n",
    "                button.click()\n",
    "                time.sleep(2)  # 클릭 후 페이지 로딩 대기\n",
    "            except ElementNotInteractableException:\n",
    "                continue\n",
    "    except NoSuchElementException:\n",
    "        print(\"리뷰 더보기 버튼을 찾을 수 없습니다.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "        break\n",
    "        \n",
    "# 개별 리뷰의 키워드 추출\n",
    "    # 페이지 로드 후 HTML 소스를 BeautifulSoup로 파싱\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        keyword_review_texts = soup.find_all('div', class_='ERkm0')\n",
    "        # 텍스트 추출\n",
    "        keyword_review_texts_list = [div.get_text() for div in keyword_review_texts]\n",
    "    except Exception as e:\n",
    "        keyword_review_texts_list = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
